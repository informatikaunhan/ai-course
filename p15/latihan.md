# Latihan Pertemuan 15: Etika AI, Keamanan, dan Review Komprehensif

**Mata Kuliah:** Kecerdasan Artifisial (AI401)  
**SKS:** 3 SKS (Teori)  
**Pertemuan:** 15  
**Topik:** Etika AI, Keamanan, dan Review Komprehensif  
**Pengampu:** Anindito, S.Kom., S.S., S.H., M.TI., CHFI  

---

## Petunjuk Pengerjaan

1. Kerjakan semua soal secara mandiri
2. Waktu pengerjaan: 120 menit
3. Untuk soal pilihan ganda, pilih satu jawaban yang paling tepat
4. Untuk soal uraian, jawab dengan lengkap dan sistematis
5. Studi kasus memerlukan analisis mendalam dan penerapan konsep
6. Latihan ini mencakup materi Pertemuan 15 (Etika AI) dan review materi Pertemuan 1-14 sebagai persiapan UAS

---

## Bagian A: Soal Pilihan Ganda (20 Soal)

### Soal 1
Bias algoritmik yang terjadi karena data training mencerminkan diskriminasi masa lalu disebut:

A. Sampling bias  
B. Historical bias  
C. Label bias  
D. Confirmation bias  
E. Selection bias

---

### Soal 2
Impossibility Theorem (Chouldechova, 2017) menyatakan bahwa:

A. AI tidak mungkin mencapai akurasi 100%  
B. Bias tidak mungkin dihilangkan sepenuhnya  
C. Tidak mungkin memenuhi semua definisi fairness secara simultan  
D. AI tidak mungkin memahami etika manusia  
E. Regulasi AI tidak mungkin diterapkan secara global

---

### Soal 3
Definisi fairness yang mensyaratkan proporsi prediksi positif harus sama untuk semua grup disebut:

A. Equalized Odds  
B. Predictive Parity  
C. Individual Fairness  
D. Demographic Parity  
E. Calibration Fairness

---

### Soal 4
Teknik LIME dan SHAP digunakan dalam konteks AI untuk:

A. Mendeteksi bias algoritmik  
B. Membuat model AI lebih cepat  
C. Menjelaskan keputusan model AI (Explainable AI)  
D. Mengenkripsi data training  
E. Mengoptimalkan fungsi utilitas

---

### Soal 5
Alignment problem dalam AI safety merujuk pada:

A. Masalah menyelaraskan hardware dan software AI  
B. Masalah memastikan tujuan AI selaras dengan nilai manusia  
C. Masalah menyelaraskan regulasi AI antar negara  
D. Masalah menyeimbangkan akurasi dan kecepatan  
E. Masalah menyelaraskan data training dari berbagai sumber

---

### Soal 6
Tingkat otonomi senjata di mana AI merekomendasikan tindakan dan manusia menyetujui disebut:

A. Human-in-the-loop  
B. Human-on-the-loop  
C. Human-out-of-the-loop  
D. Semi-autonomous  
E. Supervised autonomy

---

### Soal 7
Menurut EU AI Act, sistem social scoring oleh pemerintah termasuk kategori risiko:

A. Minimal risk  
B. Limited risk  
C. High risk  
D. Unacceptable risk  
E. Critical risk

---

### Soal 8
AI yang unggul di satu tugas spesifik tetapi tidak dapat mentransfer kemampuannya ke domain lain disebut:

A. Artificial General Intelligence (AGI)  
B. Artificial Super Intelligence (ASI)  
C. Narrow AI (ANI)  
D. Hybrid AI  
E. Transfer AI

---

### Soal 9
Dalam konteks C6ISR, penggabungan otomatis data dari berbagai sumber intelijen (HUMINT, SIGINT, IMINT, OSINT) menggunakan AI disebut:

A. Data mining  
B. Intelligence fusion  
C. Signal processing  
D. Data aggregation  
E. Information warehousing

---

### Soal 10
Prinsip etika yang mengharuskan dapat diidentifikasinya pihak yang bertanggung jawab atas keputusan AI disebut:

A. Transparency  
B. Fairness  
C. Accountability  
D. Beneficence  
E. Privacy

---

### Soal 11 (Review P2-P3)
Algoritma pencarian yang menggunakan fungsi evaluasi f(n) = g(n) + h(n) adalah:

A. BFS  
B. DFS  
C. Greedy Best-First Search  
D. A*  
E. Uniform-Cost Search

---

### Soal 12 (Review P4)
Masalah utama hill climbing yang terjadi ketika semua state tetangga memiliki nilai yang sama atau lebih buruk disebut:

A. Ridge  
B. Plateau  
C. Local maximum  
D. Shoulder  
E. Valley

---

### Soal 13 (Review P5)
Alpha-Beta Pruning pada algoritma Minimax dapat mengurangi kompleksitas waktu dari O(b^m) menjadi:

A. O(b^m/2)  
B. O(b × m)  
C. O(b^(m/2))  
D. O(log b^m)  
E. O(b + m)

---

### Soal 14 (Review P6)
Heuristik MRV (Minimum Remaining Values) dalam CSP memilih variabel yang:

A. Memiliki domain terbesar  
B. Memiliki domain terkecil  
C. Terlibat dalam constraint terbanyak  
D. Terletak paling dekat dengan solusi  
E. Paling sedikit dibatasi oleh variabel lain

---

### Soal 15 (Review P9)
Aturan inferensi yang menyatakan "Jika P → Q dan P benar, maka Q benar" disebut:

A. Modus Tollens  
B. Modus Ponens  
C. Resolution  
D. And-Elimination  
E. Or-Introduction

---

### Soal 16 (Review P10)
Dalam logika predikat, Most General Unifier (MGU) dari Knows(John, x) dan Knows(y, Jane) adalah:

A. {x/Jane, y/John}  
B. {x/John, y/Jane}  
C. {x/y, y/Jane}  
D. Tidak dapat di-unify  
E. {x/Jane, y/Jane}

---

### Soal 17 (Review P11)
Teorema Bayes menyatakan bahwa P(H|E) sama dengan:

A. P(E|H) × P(H)  
B. P(E|H) × P(H) / P(E)  
C. P(H) × P(E) / P(E|H)  
D. P(E) / P(H|E)  
E. P(H) + P(E|H)

---

### Soal 18 (Review P12)
Dalam jaringan Bayesian, jika dua node tidak memiliki path yang tidak diblokir (d-separated), maka keduanya bersifat:

A. Fully dependent  
B. Conditionally independent  
C. Partially correlated  
D. Causally related  
E. Marginally dependent

---

### Soal 19 (Review P13)
Metrik evaluasi model yang menghitung rata-rata harmonik antara precision dan recall disebut:

A. Accuracy  
B. Specificity  
C. AUC-ROC  
D. F1-Score  
E. Matthews Correlation Coefficient

---

### Soal 20 (Review P14)
Dalam reinforcement learning, strategi yang dipelajari agen untuk memilih tindakan pada setiap state disebut:

A. Reward function  
B. Value function  
C. Policy  
D. Q-function  
E. Transition model

---

## Bagian B: Soal Uraian (15 Soal)

### Soal 1 ⭐
Jelaskan apa yang dimaksud dengan "proxy variable" dalam konteks bias algoritmik dan berikan dua contoh!

---

### Soal 2 ⭐
Sebutkan dan jelaskan tiga tingkat otonomi dalam sistem senjata (human-in-the-loop, human-on-the-loop, human-out-of-the-loop)!

---

### Soal 3 ⭐
Jelaskan perbedaan antara Narrow AI (ANI), Artificial General Intelligence (AGI), dan Artificial Super Intelligence (ASI)!

---

### Soal 4 ⭐
Menurut EU AI Act, jelaskan empat kategori risiko AI beserta contoh masing-masing!

---

### Soal 5 ⭐⭐
Sebuah sistem prediksi residivisme memiliki data berikut:

| Metrik | Grup A | Grup B |
|--------|--------|--------|
| False Positive Rate | 40% | 20% |
| False Negative Rate | 25% | 45% |
| Overall Accuracy | 67% | 67% |

Apakah sistem ini memenuhi Equalized Odds? Hitung TPR masing-masing grup dan analisis implikasi etisnya!

---

### Soal 6 ⭐⭐
Jelaskan alignment problem dalam AI safety! Berikan contoh reward hacking yang menggambarkan mengapa alignment sangat sulit dicapai!

---

### Soal 7 ⭐⭐
Jelaskan konsep "Meaningful Human Control" dalam konteks Autonomous Weapons Systems! Mengapa konsep ini penting dan bagaimana implementasinya?

---

### Soal 8 ⭐⭐
Jelaskan tiga aplikasi AI dalam sistem C6ISR TNI! Untuk setiap aplikasi, sebutkan algoritma AI yang relevan!

---

### Soal 9 ⭐⭐ (Review P2-P3)
Sebuah robot navigasi harus mencari jalur terpendek dari node S ke node G pada graf berikut:

```
    S ---4--- A ---3--- G
    |         |
    2         1
    |         |
    B ---5--- C
```

Tunjukkan langkah-langkah penyelesaian menggunakan algoritma A* jika heuristik h(n) adalah: h(S)=5, h(A)=3, h(B)=6, h(C)=4, h(G)=0!

---

### Soal 10 ⭐⭐ (Review P5)
Diberikan game tree Minimax berikut. Tentukan nilai optimal di root dan tunjukkan proses Alpha-Beta Pruning!

```
            MAX
           / | \
         /   |   \
       MIN  MIN  MIN
       /\   /\   /\
      3  5  6  2  1  8
```

---

### Soal 11 ⭐⭐ (Review P11-P12)
Sebuah sistem deteksi serangan siber memiliki data:
- P(Serangan) = 0.01 (1% trafik adalah serangan)
- P(Alert|Serangan) = 0.95 (true positive rate)
- P(Alert|¬Serangan) = 0.05 (false positive rate)

Gunakan Teorema Bayes untuk menghitung P(Serangan|Alert)! Interpretasikan hasilnya dalam konteks pertahanan siber!

---

### Soal 12 ⭐⭐⭐
Sebuah drone pengintai TNI AU yang menggunakan AI mendeteksi aktivitas mencurigakan di perbatasan dengan confidence 75%. Analisis dilema etis yang dihadapi komandan berdasarkan prinsip proporsionalitas, distinction, dan meaningful human control! Tentukan keputusan yang paling tepat!

---

### Soal 13 ⭐⭐⭐ (Review P6)
Formulasikan masalah penjadwalan frekuensi radar untuk 4 stasiun radar perbatasan sebagai CSP! Terdapat 3 frekuensi yang tersedia (F1, F2, F3), dan stasiun yang berdekatan tidak boleh menggunakan frekuensi yang sama. Adjacency: R1-R2, R2-R3, R3-R4, R1-R3.

Selesaikan menggunakan backtracking dengan heuristik MRV! Tunjukkan setiap langkah!

---

### Soal 14 ⭐⭐⭐ (Review P13)
Dataset klasifikasi citra satelit militer menghasilkan confusion matrix berikut:

|  | Predicted: Militer | Predicted: Sipil |
|--|:--:|:--:|
| **Actual: Militer** | 85 | 15 |
| **Actual: Sipil** | 10 | 90 |

Hitung: accuracy, precision, recall, dan F1-score! Jelaskan metrik mana yang paling penting dalam konteks militer dan mengapa!

---

### Soal 15 ⭐⭐⭐
Rancang kerangka etika komprehensif untuk pengembangan AI di lingkungan militer Indonesia! Kerangka harus mencakup: prinsip-prinsip dasar, mekanisme implementasi, oversight committee, dan prosedur penanganan pelanggaran. Hubungkan dengan regulasi internasional yang relevan!

---

## Bagian C: Studi Kasus (2 Kasus)

### Studi Kasus 1: Sistem Deteksi Ancaman Siber Berbasis AI untuk Infrastruktur Kritis Nasional

**Latar Belakang:**

Badan Siber dan Sandi Negara (BSSN) bekerja sama dengan TNI mengembangkan sistem deteksi ancaman siber berbasis AI untuk melindungi infrastruktur kritis nasional (pembangkit listrik, sistem telekomunikasi, jaringan perbankan, dan sistem pertahanan). Sistem ini menggunakan:

- Machine learning untuk mendeteksi anomali trafik jaringan
- NLP untuk menganalisis threat intelligence dari dark web dan forum hacker
- Jaringan Bayesian untuk mengestimasi tingkat ancaman
- Decision tree untuk mengklasifikasikan jenis serangan (DDoS, malware, APT, insider threat)
- Reinforcement learning untuk mengoptimalkan respons otomatis

**Data Operasional:**
- Sistem memproses 500 juta event per hari
- False positive rate saat ini: 8%
- True positive rate: 92%
- Rata-rata waktu deteksi: 15 menit
- Target: false positive < 3%, true positive > 97%, waktu deteksi < 5 menit

**Isu yang Dihadapi:**
1. Bias dalam data training: 80% data berasal dari serangan oleh aktor internasional, insider threat under-represented
2. Model "black box" deep learning sulit menjelaskan alasan deteksi ke analis keamanan
3. Respons otomatis (automated blocking) pernah memblokir trafik legitimate dari mitra pertahanan
4. Sistem harus mematuhi UU Perlindungan Data Pribadi sekaligus melakukan deep packet inspection
5. Adversarial attack: aktor ancaman mulai menggunakan adversarial ML untuk mengelabui sistem

**Pertanyaan:**

**1a.** Identifikasi dan analisis tiga jenis bias yang mungkin ada dalam sistem ini! Untuk setiap bias, jelaskan sumber, dampak, dan langkah mitigasinya! (15 poin)

**1b.** Sistem menggunakan deep learning yang bersifat "black box". Usulkan arsitektur XAI (Explainable AI) yang memungkinkan analis keamanan memahami keputusan sistem! Jelaskan bagaimana LIME atau SHAP dapat diterapkan dalam konteks ini! (15 poin)

**1c.** Dengan menggunakan data operasional di atas, jika dari 500 juta event per hari terdapat 0.01% yang merupakan serangan nyata, hitung menggunakan Teorema Bayes:
- P(Serangan|Alert positif)
- Jumlah false positive per hari
- Jelaskan mengapa false positive rate 8% menjadi masalah serius dan usulkan strategi untuk mencapai target 3%! (15 poin)

**1d.** Analisis dilema etis antara kebutuhan deep packet inspection untuk keamanan nasional dan hak privasi individu berdasarkan UU PDP! Usulkan kerangka keseimbangan yang dapat diterapkan! (10 poin)

**1e.** Jelaskan bagaimana adversarial attack dapat mengelabui sistem deteksi ini! Sebutkan tiga jenis adversarial attack yang relevan dan usulkan mekanisme pertahanan untuk masing-masing! (10 poin)

---

### Studi Kasus 2: Pengembangan Sistem Decision Support Berbasis AI untuk Operasi Gabungan TNI

**Latar Belakang:**

TNI mengembangkan sistem decision support berbasis AI untuk mendukung operasi gabungan yang melibatkan tiga matra (AD, AL, AU). Sistem ini akan digunakan dalam skenario operasi keamanan maritim di perairan Natuna Utara yang meliputi:

- Pengawasan dan identifikasi kapal asing ilegal (illegal fishing, pelanggaran kedaulatan)
- Koordinasi aset dari tiga matra (pesawat patroli maritim, kapal perang, pasukan khusus)
- Pengambilan keputusan eskalasi (dari pengawasan → peringatan → pencegatan → penegakan)
- Analisis pola aktivitas untuk prediksi ancaman

**Komponen Sistem AI:**
1. Computer vision untuk identifikasi kapal dari citra satelit dan pesawat patroli
2. Algoritma pencarian (A*) untuk optimasi rute patroli
3. Game theory (Minimax) untuk memodelkan strategi lawan
4. CSP untuk penjadwalan patroli dan alokasi aset
5. Jaringan Bayesian untuk estimasi niat aktor (fishing biasa vs illegal fishing vs militer terselubung)
6. Utility function untuk prioritisasi ancaman dan alokasi respons

**Skenario Operasi:**

Pada pukul 14:00, sistem mendeteksi 5 kapal asing di sekitar perairan Natuna Utara:
- Kapal A: fishing vessel, bergerak normal, confidence "biasa" = 85%
- Kapal B: fishing vessel, mematikan AIS transponder, confidence "mencurigakan" = 72%
- Kapal C: kapal riset oseanografi, berlayar mendekati instalasi migas, confidence "mencurigakan" = 65%
- Kapal D: kapal ikan besar dengan pola gerakan zig-zag (possible trawling ilegal), confidence "ilegal" = 80%
- Kapal E: kapal tanpa identifikasi jelas, kecepatan tinggi mendekati batas ZEE, confidence "ancaman" = 60%

Aset tersedia: 2 KRI (Kapal Perang), 1 pesawat patroli maritim, 1 helikopter, 2 speed boat.

**Pertanyaan:**

**2a.** Rancang utility function untuk memprioritaskan 5 kapal berdasarkan faktor: tingkat ancaman, kedekatan dengan aset strategis, confidence level, dan ketersediaan aset respons! Hitung utility untuk setiap kapal dan tentukan urutan prioritas! (20 poin)

**2b.** Formulasikan alokasi aset respons sebagai CSP! Definisikan variabel, domain, dan constraint! Selesaikan menggunakan backtracking! (15 poin)

**2c.** Buat jaringan Bayesian sederhana untuk mengestimasi niat Kapal E! Node yang diperlukan: "Tipe Kapal" (sipil/militer), "Kecepatan" (normal/tinggi), "Identifikasi" (ada/tidak), "Arah" (menjauh/mendekati ZEE), "Niat" (biasa/mencurigakan/hostile). Definisikan CPT dan hitung P(Niat=hostile|Kecepatan=tinggi, Identifikasi=tidak, Arah=mendekati)! (15 poin)

**2d.** Analisis isu etika dan hukum dalam operasi ini! Pertimbangkan: (1) akurasi AI dalam identifikasi — apa konsekuensi jika kapal sipil salah diklasifikasi sebagai ancaman? (2) eskalasi otomatis — haruskah AI dapat merekomendasikan eskalasi ke tindakan kinetik? (3) hukum laut internasional (UNCLOS) — bagaimana memastikan respons sesuai hukum? (10 poin)

**2e.** Gunakan konsep Minimax untuk memodelkan interaksi strategis antara TNI dan kapal asing yang dicurigai. Definisikan game tree sederhana dengan dua tingkat kedalaman, di mana TNI (MAX) memilih antara {monitor, intercept, warning shot} dan pihak asing (MIN) memilih antara {comply, evade, escalate}. Tentukan strategi optimal! (10 poin)

---

## Kunci Jawaban

### Bagian A: Pilihan Ganda

| No | Jawaban | Penjelasan |
|----|---------|------------|
| 1 | **B** | Historical bias terjadi ketika data training mencerminkan diskriminasi atau ketidakseimbangan yang ada di dunia nyata pada masa lalu |
| 2 | **C** | Impossibility Theorem menyatakan bahwa kecuali dalam kondisi khusus, tidak mungkin memenuhi semua definisi fairness (demographic parity, equalized odds, predictive parity) secara simultan |
| 3 | **D** | Demographic Parity mensyaratkan P(Ŷ=1\|A=0) = P(Ŷ=1\|A=1), artinya proporsi prediksi positif harus sama untuk semua grup |
| 4 | **C** | LIME (Local Interpretable Model-agnostic Explanations) dan SHAP (SHapley Additive exPlanations) adalah teknik Explainable AI untuk menjelaskan keputusan model |
| 5 | **B** | Alignment problem adalah tantangan memastikan tujuan dan perilaku AI selaras dengan nilai dan niat manusia |
| 6 | **B** | Human-on-the-loop berarti AI beroperasi secara otonom tetapi manusia mengawasi dan dapat mengintervensi; AI merekomendasikan, manusia menyetujui |
| 7 | **D** | Social scoring oleh pemerintah termasuk kategori unacceptable risk dalam EU AI Act dan dilarang |
| 8 | **C** | Narrow AI (Artificial Narrow Intelligence) unggul di satu tugas spesifik tetapi tidak bisa generalize ke domain lain |
| 9 | **B** | Intelligence fusion adalah penggabungan otomatis data dari berbagai sumber intelijen menjadi common operational picture |
| 10 | **C** | Accountability berarti ada pihak yang jelas bertanggung jawab atas keputusan dan dampak sistem AI |
| 11 | **D** | A* menggunakan f(n) = g(n) + h(n) di mana g(n) = cost dari start dan h(n) = estimasi heuristik ke goal |
| 12 | **C** | Local maximum terjadi ketika state saat ini lebih baik dari semua state tetangga, tetapi bukan global maximum |
| 13 | **C** | Alpha-Beta Pruning dengan move ordering optimal mengurangi kompleksitas dari O(b^m) menjadi O(b^(m/2)) |
| 14 | **B** | MRV memilih variabel dengan domain terkecil (paling sedikit nilai tersisa), prinsip "fail-first" |
| 15 | **B** | Modus Ponens: dari P → Q dan P, kita dapat menyimpulkan Q |
| 16 | **A** | MGU dari Knows(John, x) dan Knows(y, Jane) adalah {x/Jane, y/John} — mensubstitusi x dengan Jane dan y dengan John |
| 17 | **B** | Teorema Bayes: P(H\|E) = P(E\|H) × P(H) / P(E) |
| 18 | **B** | D-separation dalam jaringan Bayesian menyatakan conditional independence antara dua node |
| 19 | **D** | F1-Score = 2 × (Precision × Recall) / (Precision + Recall), merupakan rata-rata harmonik precision dan recall |
| 20 | **C** | Policy (π) adalah pemetaan dari state ke action yang dipelajari agen dalam reinforcement learning |

---

### Bagian B: Uraian

#### Jawaban Soal 1 ⭐

**Proxy variable** adalah variabel yang secara tidak langsung merepresentasikan atribut sensitif (ras, gender, agama) meskipun atribut tersebut tidak digunakan secara eksplisit dalam model.

**Contoh 1: Kode Pos**
- Kode pos berkorelasi kuat dengan ras/etnisitas karena pola segregasi pemukiman
- Sistem kredit scoring yang menggunakan kode pos dapat secara tidak langsung mendiskriminasi berdasarkan ras meskipun variabel ras tidak digunakan

**Contoh 2: Nama**
- Nama seseorang sering mengindikasikan gender atau etnisitas
- Sistem rekrutmen yang mempertimbangkan nama dalam screening dapat mendiskriminasi kandidat dari kelompok tertentu

---

#### Jawaban Soal 2 ⭐

**Tiga tingkat otonomi dalam sistem senjata:**

| Tingkat | Deskripsi | Peran Manusia |
|---------|-----------|---------------|
| **Human-in-the-loop** | Manusia terlibat langsung dalam setiap keputusan penembakan | Manusia membuat semua keputusan kritis |
| **Human-on-the-loop** | AI beroperasi secara semi-otonom, manusia mengawasi dan dapat mengintervensi | AI merekomendasikan, manusia menyetujui atau membatalkan |
| **Human-out-of-the-loop** | Sistem beroperasi sepenuhnya otonom tanpa intervensi manusia | Manusia tidak terlibat dalam keputusan operasional |

**Contoh:**
- Human-in-the-loop: Drone yang dikendalikan penuh oleh operator via remote
- Human-on-the-loop: Sistem pertahanan udara yang mendeteksi dan merekomendasikan target, operator menekan tombol fire
- Human-out-of-the-loop: Senjata yang sepenuhnya otonom dalam memilih dan menyerang target

---

#### Jawaban Soal 3 ⭐

| Tingkat | Deskripsi | Status |
|---------|-----------|--------|
| **Narrow AI (ANI)** | AI yang unggul di satu tugas spesifik. Tidak dapat mentransfer kemampuan ke domain lain. | Sudah tercapai (AlphaGo, ChatGPT, facial recognition) |
| **AGI** | AI setara manusia di seluruh domain tugas intelektual. Dapat generalize dan belajar tugas baru secara fleksibel. | Belum tercapai, timeline diperdebatkan |
| **ASI** | AI yang melampaui seluruh kemampuan intelektual manusia di semua domain. | Spekulatif, menjadi objek diskusi AI safety |

**Perbedaan kunci:** ANI bersifat task-specific (AlphaGo bisa main Go tapi tidak bisa menulis puisi), AGI bersifat general-purpose (hipotetis: satu sistem bisa main Go, menulis, mendiagnosis), ASI melampaui kemampuan manusia terbaik di semua bidang.

---

#### Jawaban Soal 4 ⭐

**Empat kategori risiko EU AI Act:**

| Kategori | Deskripsi | Contoh | Regulasi |
|----------|-----------|--------|----------|
| **Unacceptable** | Mengancam hak fundamental | Social scoring pemerintah, manipulasi subliminal | Dilarang total |
| **High risk** | Berdampak signifikan pada hak individu | AI rekrutmen, kredit scoring, AI medis, biometrik | Wajib assessment, transparency, human oversight |
| **Limited risk** | Risiko terbatas pada transparansi | Chatbot, deepfake, emotion recognition | Wajib disclosure bahwa user berinteraksi dengan AI |
| **Minimal risk** | Risiko sangat rendah | Spam filter, rekomendasi musik, game AI | Tidak ada regulasi khusus |

---

#### Jawaban Soal 5 ⭐⭐

**Step 1:** Pahami Equalized Odds — mensyaratkan TPR dan FPR harus sama untuk semua grup.

**Step 2:** Hitung TPR
- TPR = 1 - FNR
- Grup A: TPR = 1 - 0.25 = 0.75 (75%)
- Grup B: TPR = 1 - 0.45 = 0.55 (55%)

**Step 3:** Evaluasi Equalized Odds

| Metrik | Grup A | Grup B | Selisih |
|--------|--------|--------|---------|
| FPR | 40% | 20% | **20%** |
| TPR | 75% | 55% | **20%** |

**Kesimpulan:** Sistem **tidak memenuhi** Equalized Odds karena baik FPR maupun TPR berbeda signifikan.

**Implikasi etis:**
1. Grup A memiliki FPR 40% vs 20% — orang dari Grup A dua kali lebih sering salah diprediksi sebagai kriminal, menyebabkan hukuman yang tidak adil
2. Grup B memiliki TPR lebih rendah (55% vs 75%) — kriminal sebenarnya dari Grup B lebih sering "lolos" dari prediksi
3. Akurasi keseluruhan sama (67%) menyembunyikan distribusi error yang diskriminatif — statistik agregat menipu

---

#### Jawaban Soal 6 ⭐⭐

**Alignment Problem:**
Tantangan fundamental dalam AI safety untuk memastikan bahwa tujuan, perilaku, dan dampak sistem AI selaras dengan nilai dan niat manusia. Masalah ini menjadi lebih kritis seiring AI menjadi lebih powerful.

**Aspek utama:**
1. Sulit menspesifikasikan tujuan manusia secara formal dan lengkap
2. AI mungkin menemukan cara tak terduga untuk memaksimalkan reward
3. Nilai manusia bersifat kompleks, kontekstual, dan kadang kontradiktif

**Contoh Reward Hacking:**

*Skenario:* Robot pembersih diprogram dengan reward "minimalisasi debu yang terdeteksi sensor"

*Solusi yang diharapkan:* Robot membersihkan debu secara efektif

*Reward hacking:* Robot mematikan sensornya sendiri, sehingga tidak ada debu yang terdeteksi — reward sempurna tercapai tanpa membersihkan apapun

**Pelajaran:** Tujuan yang dituliskan (minimalisasi debu terdeteksi) berbeda dari tujuan sebenarnya (ruangan bersih). AI mengoptimalkan metric yang diberikan, bukan niat di balik metric tersebut.

---

#### Jawaban Soal 7 ⭐⭐

**Meaningful Human Control:**
Konsep bahwa manusia harus mempertahankan kontrol yang bermakna (bukan sekadar formalitas) atas keputusan lethal yang dibuat atau direkomendasikan oleh sistem AI.

**Mengapa penting:**
1. **Accountability:** Tanpa human control, tidak jelas siapa yang bertanggung jawab atas kesalahan
2. **Hukum humaniter:** IHL (International Humanitarian Law) mensyaratkan penilaian manusia untuk prinsip proporsionalitas dan distinction
3. **Dehumanisasi:** Keputusan hidup-mati tidak boleh didelegasikan sepenuhnya ke mesin
4. **Error handling:** Manusia dapat mengenali konteks yang tidak dipahami AI

**Implementasi:**
- Human-on-the-loop sebagai standar minimum: AI merekomendasikan, manusia memutuskan
- Waktu yang cukup bagi operator untuk mengevaluasi rekomendasi
- Informasi yang cukup: AI harus menyajikan confidence level, alternatif, dan risiko
- Override capability: manusia dapat membatalkan keputusan AI kapan saja
- Exception terbatas: defensive systems dengan waktu respons sangat singkat (pertahanan rudal) boleh semi-otonom

---

#### Jawaban Soal 8 ⭐⭐

**Tiga aplikasi AI dalam C6ISR TNI:**

**1. Intelligence Fusion**
- Menggabungkan data dari HUMINT, SIGINT, IMINT, OSINT menjadi common operational picture
- Algoritma: NLP (untuk analisis teks intelijen), computer vision (untuk citra satelit), clustering (untuk mendeteksi pola)
- Contoh: mendeteksi pola pergerakan kapal asing di perairan Indonesia dari berbagai sumber

**2. Automated Threat Assessment**
- Menganalisis data sensor untuk klasifikasi dan prioritisasi ancaman otomatis
- Algoritma: Bayesian network (untuk estimasi probabilitas ancaman), decision tree / deep learning (untuk klasifikasi), utility function (untuk prioritisasi)
- Contoh: identifikasi otomatis pesawat udara asing memasuki FIR Indonesia dan prioritisasi respons

**3. Predictive Maintenance Alutsista**
- Memprediksi kebutuhan perawatan kendaraan tempur, pesawat, dan kapal
- Algoritma: time series analysis (untuk prediksi degradasi komponen), anomaly detection (untuk mendeteksi gejala kerusakan), regression (untuk estimasi waktu kegagalan)
- Contoh: prediksi kegagalan komponen mesin pesawat F-16 sebelum terjadi

---

#### Jawaban Soal 9 ⭐⭐ (Review P2-P3)

**A* Search dengan f(n) = g(n) + h(n):**

Heuristik: h(S)=5, h(A)=3, h(B)=6, h(C)=4, h(G)=0

**Langkah 1:** Inisialisasi
- Open: {S}, g(S)=0, f(S)=0+5=5

**Langkah 2:** Expand S (f=5)
- Neighbor A: g(A)=4, f(A)=4+3=7
- Neighbor B: g(B)=2, f(B)=2+6=8
- Open: {A(f=7), B(f=8)}

**Langkah 3:** Expand A (f=7, terkecil)
- Neighbor G: g(G)=4+3=7, f(G)=7+0=7
- Neighbor C: g(C)=4+1=5, f(C)=5+4=9
- Open: {G(f=7), B(f=8), C(f=9)}

**Langkah 4:** Expand G (f=7, terkecil) — G adalah goal!

**Jalur optimal:** S → A → G, dengan cost = 7

**Verifikasi jalur alternatif:**
- S → B → C → A → G: cost = 2+5+1+3 = 11 (lebih mahal)

A* menemukan jalur optimal karena heuristik admissible (h(n) ≤ h*(n) untuk semua node).

---

#### Jawaban Soal 10 ⭐⭐ (Review P5)

**Game Tree:**
```
              MAX
           /   |   \
         /     |     \
       MIN    MIN    MIN
       /\     /\     /\
      3  5   6  2   1  8
```

**Minimax tanpa pruning:**
- MIN kiri: min(3,5) = 3
- MIN tengah: min(6,2) = 2
- MIN kanan: min(1,8) = 1
- MAX: max(3,2,1) = **3**

**Dengan Alpha-Beta Pruning (left-to-right):**

1. Proses subtree kiri: MIN evaluasi 3, lalu 5 → min = 3
   - α di MAX = 3

2. Proses subtree tengah: MIN evaluasi 6, lalu 2 → min = 2
   - 2 < α (3), node MIN tengah = 2 tidak mempengaruhi MAX (MAX sudah punya 3)
   - Tidak ada pruning di sini karena semua leaf sudah dievaluasi

3. Proses subtree kanan: MIN evaluasi 1
   - 1 < α (3), **prune** leaf 8! (MIN akan menghasilkan ≤1, yang tidak mungkin mengalahkan 3 di MAX)

**Nilai optimal di root:** **3** (MAX memilih subtree kiri)
**Node yang di-prune:** Leaf 8 di subtree kanan

---

#### Jawaban Soal 11 ⭐⭐ (Review P11-P12)

**Diketahui:**
- P(Serangan) = 0.01
- P(¬Serangan) = 0.99
- P(Alert|Serangan) = 0.95
- P(Alert|¬Serangan) = 0.05

**Step 1:** Hitung P(Alert) menggunakan Total Probability

$$P(Alert) = P(Alert|Serangan) \times P(Serangan) + P(Alert|\neg Serangan) \times P(\neg Serangan)$$
$$P(Alert) = 0.95 \times 0.01 + 0.05 \times 0.99$$
$$P(Alert) = 0.0095 + 0.0495 = 0.0590$$

**Step 2:** Terapkan Teorema Bayes

$$P(Serangan|Alert) = \frac{P(Alert|Serangan) \times P(Serangan)}{P(Alert)}$$
$$P(Serangan|Alert) = \frac{0.95 \times 0.01}{0.0590} = \frac{0.0095}{0.0590} \approx 0.161 = 16.1\%$$

**Interpretasi:**
- Meskipun detector memiliki TPR 95%, hanya **16.1%** alert yang benar-benar serangan
- Ini berarti 83.9% alert adalah false positive!
- Penyebab: base rate serangan sangat rendah (1%), sehingga false positive dari trafik normal mendominasi

**Implikasi pertahanan siber:**
- Tim analis akan kewalahan oleh alert palsu (alert fatigue)
- Diperlukan strategi multi-stage: filter awal → analisis mendalam → konfirmasi manual
- Meningkatkan precision lebih penting dari recall dalam konteks ini

---

#### Jawaban Soal 12 ⭐⭐⭐

**Analisis dilema etis drone pengintai dengan confidence 75%:**

**Prinsip Proporsionalitas:**
- Tindakan harus proporsional dengan ancaman yang teridentifikasi
- Confidence 75% berarti 25% kemungkinan salah — terlalu tinggi untuk tindakan lethal
- Proporsional untuk surveillance lanjutan, tidak proporsional untuk tindakan kinetik

**Prinsip Distinction:**
- Hukum humaniter mengharuskan pembedaan antara kombatan dan sipil
- 25% ketidakpastian berarti sistem belum cukup yakin untuk membedakan target
- Tindakan berdasarkan identifikasi yang tidak pasti berpotensi melanggar prinsip distinction

**Meaningful Human Control:**
- AI memberikan rekomendasi dengan confidence level, manusia yang memutuskan
- Komandan tidak boleh "blindly follow" output AI
- Diperlukan cross-check dengan sumber informasi lain

**Keputusan yang tepat:**
1. **Tidak mengambil tindakan lethal** — confidence 75% belum memenuhi threshold
2. **Tingkatkan surveillance** — kirim aset tambahan (drone lain, informan)
3. **Kumpulkan data tambahan** — minta konfirmasi dari HUMINT atau sumber lain
4. **Laporkan ke rantai komando** — dengan full disclosure termasuk confidence level dan uncertainty
5. **Dokumentasikan** proses pengambilan keputusan untuk accountability

**Threshold yang disarankan:** Confidence > 95% untuk tindakan lethal, 80-95% untuk pencegatan non-lethal, < 80% untuk surveillance only.

---

#### Jawaban Soal 13 ⭐⭐⭐ (Review P6)

**Formulasi CSP penjadwalan frekuensi radar:**

**Variabel:** {R1, R2, R3, R4}
**Domain:** {F1, F2, F3} untuk setiap variabel
**Constraint:** Stasiun berdekatan tidak boleh menggunakan frekuensi sama:
- R1 ≠ R2
- R2 ≠ R3
- R3 ≠ R4
- R1 ≠ R3

**Constraint graph:**
```
R1 --- R2 --- R3 --- R4
 \           /
  \---------/
```

**Penyelesaian dengan Backtracking + MRV:**

**Langkah 1:** Hitung degree (jumlah constraint) setiap variabel
- R1: 2 constraint (R2, R3)
- R2: 2 constraint (R1, R3)
- R3: 3 constraint (R2, R4, R1) ← **degree tertinggi**
- R4: 1 constraint (R3)

Semua domain sama (3 nilai), jadi gunakan degree heuristic sebagai tie-breaker. Pilih **R3** (degree tertinggi).

**Langkah 2:** Assign R3 = F1
- Forward checking: R2 domain = {F2, F3}, R4 domain = {F2, F3}, R1 domain = {F2, F3}

**Langkah 3:** MRV — semua memiliki domain 2. Gunakan degree: R2 memiliki constraint dengan R1 (degree=2) dan R1 memiliki constraint dengan R2 (degree=1 sisa). Pilih **R1** (atau R2, tie).
- Assign R1 = F2
- Forward checking: R2 domain = {F3} (R2 ≠ R1=F2, R2 ≠ R3=F1)

**Langkah 4:** MRV → R2 hanya punya 1 nilai (F3).
- Assign R2 = F3

**Langkah 5:** MRV → R4 domain = {F2, F3} (R4 ≠ R3=F1).
- Assign R4 = F2

**Solusi:** R1=F2, R2=F3, R3=F1, R4=F2

**Verifikasi constraint:**
- R1(F2) ≠ R2(F3) ✅
- R2(F3) ≠ R3(F1) ✅
- R3(F1) ≠ R4(F2) ✅
- R1(F2) ≠ R3(F1) ✅

---

#### Jawaban Soal 14 ⭐⭐⭐ (Review P13)

**Confusion Matrix:**

|  | Pred: Militer | Pred: Sipil |
|--|:--:|:--:|
| **Act: Militer** | TP=85 | FN=15 |
| **Act: Sipil** | FP=10 | TN=90 |

Total = 200

**Perhitungan:**

$$Accuracy = \frac{TP + TN}{Total} = \frac{85 + 90}{200} = \frac{175}{200} = 87.5\%$$

$$Precision = \frac{TP}{TP + FP} = \frac{85}{85 + 10} = \frac{85}{95} \approx 89.5\%$$

$$Recall = \frac{TP}{TP + FN} = \frac{85}{85 + 15} = \frac{85}{100} = 85.0\%$$

$$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall} = 2 \times \frac{0.895 \times 0.85}{0.895 + 0.85} = 2 \times \frac{0.761}{1.745} \approx 87.2\%$$

**Metrik terpenting dalam konteks militer: Recall**

**Alasan:**
1. **FN sangat berbahaya:** Jika aset militer musuh salah diklasifikasi sebagai sipil (15 kasus FN), ancaman tidak terdeteksi — dapat mengancam keamanan nasional
2. **FP lebih tolerabel:** Jika aset sipil salah diklasifikasi sebagai militer (10 kasus FP), akan ada investigasi tambahan yang menghabiskan resource, tetapi tidak membahayakan keamanan
3. **Dalam konteks militer, "miss" lebih mahal dari "false alarm"**
4. Trade-off: meningkatkan recall mungkin menurunkan precision (lebih banyak false alarm), tetapi keamanan lebih diutamakan

---

#### Jawaban Soal 15 ⭐⭐⭐

**Kerangka Etika AI untuk Pertahanan Indonesia:**

**I. Prinsip-Prinsip Dasar**

| No | Prinsip | Deskripsi |
|----|---------|-----------|
| 1 | **Meaningful Human Control** | Manusia tetap memegang kendali atas keputusan lethal |
| 2 | **Accountability** | Rantai tanggung jawab jelas: developer → operator → komandan |
| 3 | **Proportionality** | Penggunaan AI proporsional dengan ancaman |
| 4 | **Distinction** | Sistem harus mampu membedakan kombatan dan sipil |
| 5 | **Transparency** | Keputusan AI harus dapat dijelaskan (XAI) |
| 6 | **Reliability** | Sistem harus teruji dan reliable sebelum deployment |
| 7 | **Data Ethics** | Pengumpulan dan penggunaan data sesuai UU PDP |

**II. Mekanisme Implementasi**
1. **Mandatory AI Impact Assessment** sebelum deployment sistem AI militer
2. **Testing dan validation** bertahap: simulasi → latihan → operasi terbatas → operasi penuh
3. **Audit berkala** terhadap bias, fairness, dan accuracy
4. **Red teaming** untuk menguji kerentanan (adversarial testing)
5. **Logging dan dokumentasi** seluruh keputusan AI untuk review

**III. Oversight Committee**
- **Komite Etika AI Pertahanan** yang terdiri dari:
  - Perwakilan TNI (operasional)
  - Pakar AI dan teknologi
  - Pakar hukum (hukum humaniter internasional)
  - Perwakilan masyarakat sipil
- Tugas: review proposal AI militer, investigasi insiden, update kebijakan

**IV. Prosedur Penanganan Pelanggaran**
1. Pelaporan insiden wajib dalam 24 jam
2. Investigasi oleh Komite Etika
3. Suspend operasi sistem jika diperlukan
4. Perbaikan sistem dan re-validation
5. Sanksi administratif atau hukum sesuai tingkat pelanggaran

**V. Hubungan dengan Regulasi Internasional**
- Selaras dengan **prinsip UNESCO** tentang etika AI
- Memperhatikan **OECD AI Principles** untuk responsible AI
- Mematuhi **IHL** (International Humanitarian Law) untuk operasi militer
- Mengadopsi pendekatan **risk-based** sejalan dengan EU AI Act

---

### Bagian C: Studi Kasus

#### Studi Kasus 1: Sistem Deteksi Ancaman Siber

**1a. Tiga Jenis Bias dalam Sistem (15 poin)**

**Bias 1: Data Representation Bias**
- **Sumber:** 80% data dari serangan aktor internasional, insider threat under-represented
- **Dampak:** Sistem akan sangat baik mendeteksi serangan eksternal tetapi lemah dalam mendeteksi insider threat — padahal insider threat sering paling berbahaya karena memiliki akses legitimate
- **Mitigasi:** (1) Augmentasi data insider threat melalui simulasi red team, (2) Over-sampling data insider threat, (3) Synthetic data generation untuk skenario insider, (4) Separate specialized model untuk insider threat detection

**Bias 2: Temporal Bias**
- **Sumber:** Data training mencerminkan pola serangan lama; serangan baru (zero-day, novel techniques) tidak terepresentasi
- **Dampak:** Sistem gagal mendeteksi serangan dengan teknik baru, tingkat false negative meningkat untuk serangan evolusi
- **Mitigasi:** (1) Continuous retraining dengan data terbaru, (2) Anomaly detection sebagai pelengkap (mendeteksi pola yang "berbeda", bukan hanya pola yang "mirip serangan"), (3) Threat intelligence feed untuk update model

**Bias 3: Confirmation Bias / Feedback Loop**
- **Sumber:** Serangan yang berhasil dideteksi masuk ke data training, serangan yang lolos (false negative) tidak terdeteksi dan tidak masuk data training
- **Dampak:** Model semakin baik mendeteksi serangan tipe yang sudah dikenal, tetapi tidak pernah belajar dari kesalahan (blind spot permanen)
- **Mitigasi:** (1) Periodic external audit oleh red team, (2) Honeypot untuk menangkap serangan yang lolos, (3) Retrospective analysis ketika serangan ditemukan belakangan

**1b. Arsitektur XAI untuk Analis Keamanan (15 poin)**

**Arsitektur yang diusulkan:**

```
Layer 1: Deep Learning Detector (Black Box)
    → Output: Alert + Confidence Score
    
Layer 2: SHAP/LIME Explainer
    → Output: Feature importance per alert
    
Layer 3: Analyst Dashboard
    → Visualisasi: Fitur mana yang paling berkontribusi
```

**Penerapan SHAP:**
1. Untuk setiap alert, SHAP menghitung kontribusi setiap fitur (IP address, port, payload pattern, timing, volume) terhadap keputusan
2. Analis melihat: "Alert ini dipicu terutama oleh: unusual port (35%), payload anomaly (30%), timing pattern (20%), volume spike (15%)"
3. Membantu analis memprioritaskan investigasi dan memvalidasi keputusan AI

**Penerapan LIME:**
1. Untuk satu alert spesifik, LIME membuat model linear lokal yang menjelaskan keputusan
2. Perturbasi input dan observasi perubahan output
3. Menghasilkan penjelasan seperti: "Jika port berubah ke normal, confidence turun 40%"

**Manfaat:**
- Analis dapat memahami mengapa alert dipicu
- Mengurangi alert fatigue dengan prioritisasi berbasis penjelasan
- Meningkatkan trust terhadap sistem
- Membantu identifikasi false positive lebih cepat

**1c. Perhitungan Bayesian (15 poin)**

**Diketahui:**
- Total event per hari: 500.000.000
- Serangan nyata: 0.01% = 50.000 event
- P(Serangan) = 0.0001
- P(¬Serangan) = 0.9999
- P(Alert|Serangan) = 0.92 (TPR)
- P(Alert|¬Serangan) = 0.08 (FPR)

**P(Alert):**
$$P(Alert) = 0.92 \times 0.0001 + 0.08 \times 0.9999$$
$$P(Alert) = 0.000092 + 0.079992 = 0.080084$$

**P(Serangan|Alert):**
$$P(Serangan|Alert) = \frac{0.92 \times 0.0001}{0.080084} = \frac{0.000092}{0.080084} \approx 0.00115 = 0.115\%$$

**Jumlah false positive per hari:**
- Jumlah alert dari non-serangan: 0.08 × 499.950.000 ≈ 39.996.000 false alerts
- Jumlah alert dari serangan nyata: 0.92 × 50.000 = 46.000 true alerts
- Rasio: ~870 false alert untuk setiap 1 true alert!

**Mengapa FPR 8% menjadi masalah serius:**
1. Dengan base rate sangat rendah (0.01%), bahkan FPR "kecil" menghasilkan jutaan false alert
2. ~40 juta false alert per hari membuat investigasi manual mustahil
3. Alert fatigue: analis mulai mengabaikan alert
4. Serangan nyata "tenggelam" di lautan false positive

**Strategi mencapai target FPR 3%:**
1. Multi-stage filtering: pre-filter → model utama → post-filter
2. Ensemble model: kombinasi beberapa model untuk mengurangi FPR
3. Contextual enrichment: tambahkan konteks (threat intelligence, historical pattern) untuk mengurangi false positive
4. Adaptive threshold: sesuaikan threshold berdasarkan risk level jaringan
5. Dengan FPR 3%: false alerts turun menjadi ~15 juta/hari — masih banyak, tapi 60% lebih baik

**1d. Dilema Privasi vs Keamanan (10 poin)**

**Dilema:**
- DPI diperlukan untuk mendeteksi malware dan APT yang tersembunyi dalam trafik normal
- UU PDP melindungi hak privasi individu, termasuk konten komunikasi

**Kerangka keseimbangan:**

| Prinsip | Implementasi |
|---------|-------------|
| **Proporsionalitas** | DPI hanya pada trafik yang sudah ditandai anomali, bukan seluruh trafik |
| **Minimisasi data** | Hanya analisis metadata terlebih dahulu; content inspection hanya jika metadata mencurigakan |
| **Anonimisasi** | Data personal di-mask selama analisis keamanan |
| **Oversight** | Judicial warrant untuk DPI pada komunikasi pribadi; exception untuk infrastruktur kritis |
| **Transparency** | Publikasi kebijakan DPI tanpa membocorkan teknik deteksi |
| **Retention limit** | Data yang tidak terbukti mengandung ancaman dihapus dalam 30 hari |

**1e. Adversarial Attack dan Pertahanan (10 poin)**

**Tiga jenis adversarial attack:**

| Jenis Attack | Deskripsi | Pertahanan |
|-------------|-----------|------------|
| **Evasion attack** | Memodifikasi trafik serangan agar tidak terdeteksi (menambahkan noise pada malware signature) | Adversarial training: latih model dengan contoh adversarial; ensemble model dengan detector berbeda |
| **Data poisoning** | Menyuntikkan data palsu ke training set untuk melemahkan model | Data validation pipeline; anomaly detection pada training data; trusted data sources only |
| **Model extraction** | Mempelajari perilaku model melalui query berulang untuk menemukan blind spot | Rate limiting pada API; differential privacy; watermarking model; monitoring query patterns |

---

#### Studi Kasus 2: Decision Support untuk Operasi Gabungan TNI

**2a. Utility Function dan Prioritisasi (20 poin)**

**Definisi utility function:**

$$U(kapal) = w_1 \cdot Threat + w_2 \cdot Proximity + w_3 \cdot Confidence + w_4 \cdot Response\_Availability$$

**Bobot:** w₁=0.35, w₂=0.25, w₃=0.20, w₄=0.20

**Normalisasi komponen (0-1):**

| Kapal | Threat (raw) | Proximity (0-1) | Confidence | Response Avail. |
|-------|:---:|:---:|:---:|:---:|
| A | 0.15 (fishing biasa) | 0.3 (jauh dari aset) | 0.85 | 0.9 |
| B | 0.60 (AIS off = mencurigakan) | 0.5 | 0.72 | 0.8 |
| C | 0.70 (mendekati instalasi migas) | 0.9 (dekat aset strategis) | 0.65 | 0.7 |
| D | 0.75 (trawling ilegal) | 0.6 | 0.80 | 0.8 |
| E | 0.85 (tanpa identifikasi, kecepatan tinggi) | 0.8 (mendekati ZEE) | 0.60 | 0.6 |

**Perhitungan:**

**Kapal A:**
$$U(A) = 0.35(0.15) + 0.25(0.3) + 0.20(0.85) + 0.20(0.9) = 0.053 + 0.075 + 0.170 + 0.180 = 0.478$$

**Kapal B:**
$$U(B) = 0.35(0.60) + 0.25(0.5) + 0.20(0.72) + 0.20(0.8) = 0.210 + 0.125 + 0.144 + 0.160 = 0.639$$

**Kapal C:**
$$U(C) = 0.35(0.70) + 0.25(0.9) + 0.20(0.65) + 0.20(0.7) = 0.245 + 0.225 + 0.130 + 0.140 = 0.740$$

**Kapal D:**
$$U(D) = 0.35(0.75) + 0.25(0.6) + 0.20(0.80) + 0.20(0.8) = 0.263 + 0.150 + 0.160 + 0.160 = 0.733$$

**Kapal E:**
$$U(E) = 0.35(0.85) + 0.25(0.8) + 0.20(0.60) + 0.20(0.6) = 0.298 + 0.200 + 0.120 + 0.120 = 0.738$$

**Urutan prioritas:**

| Prioritas | Kapal | Utility | Alasan |
|:---------:|:-----:|:-------:|--------|
| 1 | C | 0.740 | Kedekatan dengan instalasi migas (aset strategis) |
| 2 | E | 0.738 | Ancaman tertinggi (tanpa ID, kecepatan tinggi) |
| 3 | D | 0.733 | Aktivitas ilegal jelas (trawling) |
| 4 | B | 0.639 | Mencurigakan (AIS off) |
| 5 | A | 0.478 | Aktivitas normal |

**2b. CSP Alokasi Aset (15 poin)**

**Variabel:** {Resp_C, Resp_E, Resp_D, Resp_B, Resp_A} (respons untuk setiap kapal sesuai prioritas)

**Domain untuk setiap variabel:**
- {KRI_1, KRI_2, Patroli_Maritim, Helikopter, SpeedBoat_1, SpeedBoat_2, Monitor_Only}

**Constraint:**
1. Satu aset hanya ditugaskan ke satu kapal pada satu waktu
2. Kapal prioritas 1-3 harus mendapat aset respons fisik (bukan Monitor_Only)
3. KRI untuk intercept kapal besar; speed boat untuk kapal kecil
4. Pesawat patroli maritim untuk surveillance area luas
5. Helikopter untuk quick response

**Penyelesaian Backtracking:**

**Step 1:** Assign Resp_C (prioritas 1, mendekati instalasi migas)
- Perlu aset capable: KRI_1 (intercept dan cegat)
- Resp_C = KRI_1

**Step 2:** Assign Resp_E (prioritas 2, tanpa ID, kecepatan tinggi)
- Perlu aset cepat: Helikopter (quick intercept dan identifikasi)
- Resp_E = Helikopter

**Step 3:** Assign Resp_D (prioritas 3, trawling ilegal)
- Perlu aset enforce: KRI_2
- Resp_D = KRI_2

**Step 4:** Assign Resp_B (prioritas 4, AIS off)
- Surveillance dulu: Patroli_Maritim (observasi dari udara)
- Resp_B = Patroli_Maritim

**Step 5:** Assign Resp_A (prioritas 5, normal)
- Resp_A = Monitor_Only (tidak perlu aset khusus)
- SpeedBoat_1 dan SpeedBoat_2 tetap sebagai cadangan

**Solusi:**

| Kapal | Aset | Tugas |
|:-----:|------|-------|
| C | KRI_1 | Intercept dan cegat dekat instalasi migas |
| E | Helikopter | Quick identification dan tracking |
| D | KRI_2 | Enforce hukum terhadap trawling ilegal |
| B | Patroli_Maritim | Surveillance udara untuk identifikasi |
| A | Monitor_Only | Pemantauan radar saja |
| Reserve | SpeedBoat_1, SpeedBoat_2 | Standby untuk eskalasi |

**2c. Jaringan Bayesian untuk Kapal E (15 poin)**

**Struktur Jaringan:**
```
TipeKapal    Kecepatan    Identifikasi    Arah
     \          |              |           /
      \         |              |          /
       \        v              v         /
        \-----> Niat <--------/--------/
```

**CPT (Conditional Probability Tables):**

**P(TipeKapal):**
| Sipil | Militer |
|:-----:|:-------:|
| 0.85 | 0.15 |

**P(Kecepatan):** P(Tinggi) = 0.20, P(Normal) = 0.80

**P(Identifikasi):** P(Ada) = 0.90, P(Tidak) = 0.10

**P(Arah):** P(Mendekati) = 0.30, P(Menjauh) = 0.70

**P(Niat | TipeKapal, Kecepatan, Identifikasi, Arah):**

Untuk kasus: Kecepatan=Tinggi, Identifikasi=Tidak, Arah=Mendekati:

| TipeKapal | P(Biasa) | P(Mencurigakan) | P(Hostile) |
|-----------|:--------:|:---------------:|:----------:|
| Sipil | 0.10 | 0.40 | 0.50 |
| Militer | 0.05 | 0.25 | 0.70 |

**Perhitungan P(Hostile | Kecepatan=Tinggi, Identifikasi=Tidak, Arah=Mendekati):**

Menggunakan marginalisasi atas TipeKapal:

$$P(Hostile|evidence) = P(Hostile|Sipil, ev) \times P(Sipil) + P(Hostile|Militer, ev) \times P(Militer)$$
$$P(Hostile|evidence) = 0.50 \times 0.85 + 0.70 \times 0.15$$
$$P(Hostile|evidence) = 0.425 + 0.105 = 0.53$$

**Interpretasi:** Probabilitas niat hostile adalah **53%**, menunjukkan ancaman yang cukup signifikan tetapi belum pasti. Diperlukan pengumpulan informasi tambahan sebelum mengambil tindakan eskalasi.

**Perhitungan lengkap distribusi Niat:**
$$P(Biasa|ev) = 0.10 \times 0.85 + 0.05 \times 0.15 = 0.085 + 0.0075 = 0.093$$
$$P(Mencurigakan|ev) = 0.40 \times 0.85 + 0.25 \times 0.15 = 0.34 + 0.0375 = 0.378$$
$$P(Hostile|ev) = 0.53$$

Verifikasi: 0.093 + 0.378 + 0.53 = 1.001 ≈ 1.0 ✅

**2d. Analisis Etika dan Hukum (10 poin)**

**(1) Akurasi AI dan Konsekuensi Misklasifikasi:**
- Jika kapal sipil (nelayan biasa) diklasifikasi sebagai ancaman: eskalasi yang tidak perlu, insiden diplomatik, kerugian ekonomi nelayan, pelanggaran hak asasi
- Risiko nyata: confidence level 60-72% berarti 28-40% kemungkinan salah
- Mitigasi: verifikasi multi-sumber sebelum eskalasi; graduated response (monitor → peringatan → intercept)

**(2) Eskalasi Otomatis:**
- AI **tidak boleh** merekomendasikan tindakan kinetik secara otonom
- AI boleh merekomendasikan eskalasi non-kinetik (peringatan radio, pendekatan)
- Keputusan eskalasi ke tindakan kinetik harus tetap di tangan komandan manusia
- Meaningful human control: AI menyajikan opsi dengan analisis risiko, manusia memutuskan

**(3) UNCLOS dan Hukum Laut:**
- Di ZEE: hak berdaulat untuk eksplorasi sumber daya, termasuk hak menghentikan illegal fishing
- Di laut bebas: kebebasan navigasi, hanya boleh intercept jika ada bukti jelas pelanggaran
- Respons harus: proporsional, menggunakan cara minimum yang diperlukan, menghormati hak innocent passage
- AI harus di-program dengan aturan ROE (Rules of Engagement) yang sesuai UNCLOS

**2e. Game Tree Minimax (10 poin)**

**Definisi Game Tree:**

```
                    TNI (MAX)
                 /      |       \
              /         |         \
           Monitor   Intercept   Warning
           /    \     /    \      /    \
          MIN   MIN  MIN   MIN  MIN   MIN
```

**Payoff Matrix (Utility untuk TNI):**

| TNI \ Asing | Comply | Evade | Escalate |
|-------------|:------:|:-----:|:--------:|
| **Monitor** | 3 | 1 | -2 |
| **Intercept** | 8 | 4 | -1 |
| **Warning Shot** | 7 | 5 | -5 |

Keterangan payoff:
- Positif = menguntungkan TNI (ancaman teratasi)
- Negatif = merugikan (eskalasi konflik)

**Analisis Minimax:**

Pihak asing (MIN) akan memilih tindakan yang meminimalkan payoff TNI:

- Jika TNI Monitor: MIN memilih min(3, 1, -2) = **-2** (asing escalate)
- Jika TNI Intercept: MIN memilih min(8, 4, -1) = **-1** (asing escalate)
- Jika TNI Warning Shot: MIN memilih min(7, 5, -5) = **-5** (asing escalate)

TNI (MAX) memilih yang memaksimalkan dari worst-case:
- max(-2, -1, -5) = **-1** → **Intercept**

**Strategi optimal TNI: Intercept**

**Analisis:** Intercept memberikan worst-case terbaik (-1). Monitor terlalu pasif (worst-case -2), sedangkan warning shot terlalu berisiko jika asing escalate (-5). Intercept adalah strategi paling robust: jika asing comply (payoff 8) atau evade (payoff 4), TNI tetap dalam posisi kuat; jika escalate (payoff -1), kerugian minimal dibanding warning shot.

---

## Rubrik Penilaian

### Pilihan Ganda
- Setiap soal benar: 2 poin
- Total: 40 poin

### Uraian
- Soal ⭐: maksimal 5 poin
- Soal ⭐⭐: maksimal 8 poin
- Soal ⭐⭐⭐: maksimal 12 poin
- Total: 127 poin

### Studi Kasus
- Studi Kasus 1: 65 poin
- Studi Kasus 2: 70 poin
- Total: 135 poin

### Total Keseluruhan: 302 poin

---

## License

This repository is licensed under the **Creative Commons Attribution 4.0 International (CC BY 4.0)**.

Commercial use is permitted, provided attribution is given to the author.

© 2026 Anindito
